version: '3.4'

volumes:
  weaviate_data:
  minio_data:
  translation_model_data:  # Define volume for translation service model data
  embedding_model_data: 

services:
  weaviate:
    command:
    - --host
    - 0.0.0.0
    - --port
    - '8080'
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.25.4
    ports:
    - 9000:8080
    - 50051:50051
    volumes:
    - weaviate_data:/var/lib/weaviate
    restart: on-failure:0
    environment:
      QUERY_DEFAULTS_LIMIT: 10000
      QUERY_MAXIMUM_RESULTS : 100000
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      CLUSTER_HOSTNAME: 'node1'
    
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9002:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_DEFAULT_BUCKETS=${MINIO_DEFAULT_BUCKETS}
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  vector_db_interface:
    container_name: vector-db-interface
    build: 
      context: ./vector_db_interface
    env_file: .env
    ports:
      - "50053:50051"
    depends_on:
      - "weaviate"
    restart: always
  
  chat_interface:
    build: 
      context: ./chat_interface
    env_file: .env
    ports:
      - "50055-50056:50055"
    depends_on:
      - "weaviate"
    restart: always
    deploy:
      mode: replicated
      replicas: 1
      endpoint_mode: vip

  ui_service:
    container_name: ui-service
    build: 
      context: ./ui_service
    env_file: .env
    ports:
      - "7860:7860"
    depends_on:
      - "weaviate"
      - "vector_db_interface"
    restart: always

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  
  nginx:
      image: nginx:latest
      ports:
        - "8081:8080"  # Expose nginx on port 8080 of the host
        - "19000:19000"
      volumes:
        - ./nginx.conf:/etc/nginx/nginx.conf:ro  # Mount custom nginx configuration
      depends_on:
      - "chat_interface"
      restart: always

  embedding_service:
    container_name: embedding_service
    build: 
      context: ./embedding_service
    env_file: .env
    ports:
    - "8000:8000"
    - "8088:8088" # for dashboard
    restart: always
    volumes:
      - embedding_model_data:/root/.cache/huggingface/transformers  # Mount volume for embedding service model data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  translation_service:
    container_name: translation_service
    build: 
      context: ./translation_service
    env_file: .env
    ports:
    - "8251:8000"
    restart: always
    volumes:
      - translation_model_data:/root/.cache/huggingface/transformers  # Mount volume for embedding service model data
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]